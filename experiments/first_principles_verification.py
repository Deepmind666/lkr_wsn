#!/usr/bin/env python3
"""
ç¬¬ä¸€æ€§åŸç†éªŒè¯è„šæœ¬
éªŒè¯Enhanced EEHFR 2.0 vs PEGASISçš„èƒ½æ•ˆå’ŒæŠ•é€’ç‡å·®å¼‚çš„æœ¬è´¨åŸå› 
"""

import math
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Tuple
import json

class FirstPrinciplesAnalyzer:
    """ç¬¬ä¸€æ€§åŸç†åˆ†æå™¨"""
    
    def __init__(self):
        # ç½‘ç»œå‚æ•°
        self.num_nodes = 50
        self.area_size = 100  # 100m x 100m
        self.base_station = (50, 50)
        self.initial_energy = 2.0  # J
        
        # èƒ½è€—å‚æ•° (CC2420)
        self.E_circuit = 50e-9  # 50 nJ/bit
        self.E_amp = 100e-12    # 100 pJ/bit/mÂ²
        self.packet_size = 1024 * 8  # 1024 bytes = 8192 bits
        
        # åè®®å‚æ•°
        self.cluster_head_percentage = 0.15  # 15%ç°‡å¤´æ¯”ä¾‹
        self.pegasis_success_rate = 0.98
        self.enhanced_success_rate = 0.95
        
    def generate_random_topology(self, seed: int = 42) -> List[Tuple[float, float]]:
        """ç”Ÿæˆéšæœºç½‘ç»œæ‹“æ‰‘"""
        np.random.seed(seed)
        nodes = []
        for _ in range(self.num_nodes):
            x = np.random.uniform(0, self.area_size)
            y = np.random.uniform(0, self.area_size)
            nodes.append((x, y))
        return nodes
    
    def calculate_distance(self, node1: Tuple[float, float], node2: Tuple[float, float]) -> float:
        """è®¡ç®—ä¸¤ç‚¹é—´è·ç¦»"""
        return math.sqrt((node1[0] - node2[0])**2 + (node1[1] - node2[1])**2)
    
    def calculate_transmission_energy(self, distance: float) -> float:
        """è®¡ç®—ä¼ è¾“èƒ½è€—"""
        return self.E_circuit * self.packet_size + self.E_amp * self.packet_size * (distance ** 2)
    
    def analyze_pegasis_energy(self, nodes: List[Tuple[float, float]]) -> dict:
        """åˆ†æPEGASISåè®®çš„èƒ½è€—ç‰¹å¾"""
        # æ„å»ºPEGASISé“¾
        remaining = nodes.copy()
        
        # æ‰¾åˆ°è·ç¦»åŸºç«™æœ€è¿œçš„èŠ‚ç‚¹ä½œä¸ºèµ·ç‚¹
        start_node = max(remaining, key=lambda n: self.calculate_distance(n, self.base_station))
        chain = [start_node]
        remaining.remove(start_node)
        
        # è´ªå¿ƒæ„å»ºé“¾
        current = start_node
        while remaining:
            nearest = min(remaining, key=lambda n: self.calculate_distance(current, n))
            chain.append(nearest)
            remaining.remove(nearest)
            current = nearest
        
        # è®¡ç®—é“¾å¼ä¼ è¾“èƒ½è€—
        total_energy = 0.0
        transmission_distances = []
        
        # é“¾å†…ä¼ è¾“
        for i in range(len(chain) - 1):
            distance = self.calculate_distance(chain[i], chain[i + 1])
            energy = self.calculate_transmission_energy(distance)
            total_energy += energy
            transmission_distances.append(distance)
        
        # é¢†å¯¼è€…åˆ°åŸºç«™ä¼ è¾“
        leader_index = len(chain) // 2
        leader = chain[leader_index]
        bs_distance = self.calculate_distance(leader, self.base_station)
        bs_energy = self.calculate_transmission_energy(bs_distance)
        total_energy += bs_energy
        
        return {
            'total_energy': total_energy,
            'chain_length': len(chain),
            'transmission_count': len(chain),  # åŒ…æ‹¬åˆ°åŸºç«™çš„ä¼ è¾“
            'avg_chain_distance': np.mean(transmission_distances),
            'max_chain_distance': max(transmission_distances),
            'bs_distance': bs_distance,
            'bs_energy': bs_energy,
            'chain_energy': total_energy - bs_energy,
            'expected_packets_received': self.num_nodes * self.pegasis_success_rate
        }
    
    def analyze_enhanced_eehfr_energy(self, nodes: List[Tuple[float, float]]) -> dict:
        """åˆ†æEnhanced EEHFR 2.0åè®®çš„èƒ½è€—ç‰¹å¾"""
        # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„ç°‡å¤´æ¦‚ç‡
        node_probabilities = []
        for node in nodes:
            # èƒ½é‡å› å­ (å‡è®¾æ‰€æœ‰èŠ‚ç‚¹åˆå§‹èƒ½é‡ç›¸åŒ)
            energy_factor = 1.0
            
            # ä½ç½®å› å­
            distance_to_bs = self.calculate_distance(node, self.base_station)
            max_distance = math.sqrt(2) * self.area_size
            position_factor = 1.0 - (distance_to_bs / max_distance)
            
            # ä¸­å¿ƒæ€§å› å­
            avg_distance = np.mean([self.calculate_distance(node, other) for other in nodes if other != node])
            max_avg_distance = max_distance / 2
            centrality_factor = 1.0 - (avg_distance / max_avg_distance)
            
            # ç»¼åˆæ¦‚ç‡
            probability = 0.4 * energy_factor + 0.3 * position_factor + 0.3 * centrality_factor
            node_probabilities.append((node, probability, distance_to_bs))
        
        # é€‰æ‹©ç°‡å¤´
        num_cluster_heads = max(1, int(self.num_nodes * self.cluster_head_percentage))
        sorted_nodes = sorted(node_probabilities, key=lambda x: x[1], reverse=True)
        cluster_heads = sorted_nodes[:num_cluster_heads]
        
        # è®¡ç®—ç°‡å†…ä¼ è¾“èƒ½è€—
        total_energy = 0.0
        intra_cluster_distances = []
        inter_cluster_distances = []
        
        # ä¸ºæ¯ä¸ªéç°‡å¤´èŠ‚ç‚¹åˆ†é…åˆ°æœ€è¿‘çš„ç°‡å¤´
        non_cluster_heads = [node for node, _, _ in sorted_nodes[num_cluster_heads:]]
        
        for member in non_cluster_heads:
            # æ‰¾åˆ°æœ€è¿‘çš„ç°‡å¤´
            nearest_head = min(cluster_heads, key=lambda ch: self.calculate_distance(member, ch[0]))
            distance = self.calculate_distance(member, nearest_head[0])
            energy = self.calculate_transmission_energy(distance)
            total_energy += energy
            intra_cluster_distances.append(distance)
        
        # ç°‡å¤´åˆ°åŸºç«™ä¼ è¾“
        for head, _, bs_distance in cluster_heads:
            energy = self.calculate_transmission_energy(bs_distance)
            total_energy += energy
            inter_cluster_distances.append(bs_distance)
        
        return {
            'total_energy': total_energy,
            'num_cluster_heads': num_cluster_heads,
            'transmission_count': len(non_cluster_heads) + num_cluster_heads,
            'bs_transmission_count': num_cluster_heads,
            'avg_intra_distance': np.mean(intra_cluster_distances) if intra_cluster_distances else 0,
            'avg_inter_distance': np.mean(inter_cluster_distances),
            'max_inter_distance': max(inter_cluster_distances),
            'min_inter_distance': min(inter_cluster_distances),
            'intra_cluster_energy': total_energy - sum(self.calculate_transmission_energy(d) for d in inter_cluster_distances),
            'inter_cluster_energy': sum(self.calculate_transmission_energy(d) for d in inter_cluster_distances),
            'expected_packets_received': num_cluster_heads * self.enhanced_success_rate
        }
    
    def run_comparative_analysis(self) -> dict:
        """è¿è¡Œå¯¹æ¯”åˆ†æ"""
        print("ğŸ”¬ å¼€å§‹ç¬¬ä¸€æ€§åŸç†éªŒè¯åˆ†æ...")
        
        # ç”Ÿæˆç½‘ç»œæ‹“æ‰‘
        nodes = self.generate_random_topology()
        
        # åˆ†æPEGASIS
        print("ğŸ“Š åˆ†æPEGASISåè®®...")
        pegasis_results = self.analyze_pegasis_energy(nodes)
        
        # åˆ†æEnhanced EEHFR 2.0
        print("ğŸ“Š åˆ†æEnhanced EEHFR 2.0åè®®...")
        enhanced_results = self.analyze_enhanced_eehfr_energy(nodes)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        pegasis_efficiency = self.num_nodes / pegasis_results['total_energy']
        enhanced_efficiency = self.num_nodes / enhanced_results['total_energy']
        
        pegasis_pdr = pegasis_results['expected_packets_received'] / self.num_nodes
        enhanced_pdr = enhanced_results['expected_packets_received'] / self.num_nodes
        
        # è®¡ç®—æå‡å¹…åº¦
        efficiency_improvement = (enhanced_efficiency - pegasis_efficiency) / pegasis_efficiency * 100
        pdr_change = (enhanced_pdr - pegasis_pdr) / pegasis_pdr * 100
        
        results = {
            'pegasis': pegasis_results,
            'enhanced': enhanced_results,
            'comparison': {
                'pegasis_efficiency': pegasis_efficiency,
                'enhanced_efficiency': enhanced_efficiency,
                'efficiency_improvement_percent': efficiency_improvement,
                'pegasis_pdr': pegasis_pdr,
                'enhanced_pdr': enhanced_pdr,
                'pdr_change_percent': pdr_change
            }
        }
        
        return results
    
    def print_analysis_results(self, results: dict):
        """æ‰“å°åˆ†æç»“æœ"""
        print("\n" + "="*80)
        print("ğŸ¯ ç¬¬ä¸€æ€§åŸç†éªŒè¯ç»“æœ")
        print("="*80)
        
        pegasis = results['pegasis']
        enhanced = results['enhanced']
        comp = results['comparison']
        
        print(f"\nğŸ“Š PEGASISåè®®åˆ†æ:")
        print(f"   æ€»èƒ½è€—: {pegasis['total_energy']:.6f} J")
        print(f"   ä¼ è¾“æ¬¡æ•°: {pegasis['transmission_count']}")
        print(f"   å¹³å‡é“¾è·ç¦»: {pegasis['avg_chain_distance']:.2f} m")
        print(f"   åŸºç«™è·ç¦»: {pegasis['bs_distance']:.2f} m")
        print(f"   èƒ½æ•ˆ: {comp['pegasis_efficiency']:.2f} packets/J")
        print(f"   æŠ•é€’ç‡: {comp['pegasis_pdr']:.3f}")
        
        print(f"\nğŸ“Š Enhanced EEHFR 2.0åè®®åˆ†æ:")
        print(f"   æ€»èƒ½è€—: {enhanced['total_energy']:.6f} J")
        print(f"   ç°‡å¤´æ•°é‡: {enhanced['num_cluster_heads']}")
        print(f"   åŸºç«™ä¼ è¾“æ¬¡æ•°: {enhanced['bs_transmission_count']}")
        print(f"   å¹³å‡ç°‡å†…è·ç¦»: {enhanced['avg_intra_distance']:.2f} m")
        print(f"   å¹³å‡ç°‡é—´è·ç¦»: {enhanced['avg_inter_distance']:.2f} m")
        print(f"   èƒ½æ•ˆ: {comp['enhanced_efficiency']:.2f} packets/J")
        print(f"   æŠ•é€’ç‡: {comp['enhanced_pdr']:.3f}")
        
        print(f"\nğŸ¯ æ€§èƒ½å¯¹æ¯”:")
        print(f"   èƒ½æ•ˆæå‡: {comp['efficiency_improvement_percent']:+.2f}%")
        print(f"   æŠ•é€’ç‡å˜åŒ–: {comp['pdr_change_percent']:+.2f}%")
        
        print(f"\nğŸ” æœ¬è´¨åŸå› åˆ†æ:")
        print(f"   ä¼ è¾“æ¬¡æ•°å¯¹æ¯”: {pegasis['transmission_count']} vs {enhanced['bs_transmission_count']} (åˆ°åŸºç«™)")
        print(f"   èƒ½è€—åˆ†å¸ƒ: PEGASISé“¾å¼ä¼ è¾“ vs Enhancedä¸¤é˜¶æ®µä¼ è¾“")
        print(f"   è·ç¦»ä¼˜åŒ–: Enhancedå¹³å‡ç°‡é—´è·ç¦» {enhanced['avg_inter_distance']:.1f}m")
        
        # éªŒè¯ä¸å®é™…å®éªŒç»“æœçš„ä¸€è‡´æ€§
        print(f"\nâœ… ä¸å®é™…å®éªŒç»“æœå¯¹æ¯”:")
        print(f"   ç†è®ºèƒ½æ•ˆæå‡: {comp['efficiency_improvement_percent']:+.2f}% vs å®é™…: +5.54%")
        print(f"   ç†è®ºæŠ•é€’ç‡å˜åŒ–: {comp['pdr_change_percent']:+.2f}% vs å®é™…: -3.95%")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = FirstPrinciplesAnalyzer()
    results = analyzer.run_comparative_analysis()
    analyzer.print_analysis_results(results)
    
    # ä¿å­˜ç»“æœ
    with open('first_principles_analysis_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: first_principles_analysis_results.json")

if __name__ == "__main__":
    main()
