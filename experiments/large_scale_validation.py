#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced PEGASIS å¤§è§„æ¨¡ç½‘ç»œéªŒè¯å®éªŒ
éªŒè¯ç®—æ³•åœ¨100ã€200ã€500èŠ‚ç‚¹è§„æ¨¡ä¸‹çš„å¯æ‰©å±•æ€§å’Œæ€§èƒ½ç¨³å®šæ€§

ç›®æ ‡: ç¡®ä¿Enhanced PEGASISåœ¨å¤§è§„æ¨¡ç½‘ç»œä¸­ä¿æŒ90%+æ€§èƒ½æå‡

ä½œè€…: Enhanced EEHFR Research Team
æ—¥æœŸ: 2025-01-30
ç‰ˆæœ¬: 1.0
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from enhanced_pegasis import EnhancedPEGASISProtocol, EnhancedPEGASISConfig
from benchmark_protocols import PEGASISProtocol, NetworkConfig
from improved_energy_model import ImprovedEnergyModel, HardwarePlatform
import time
import json
import statistics
from datetime import datetime
import matplotlib.pyplot as plt
import numpy as np

def test_scalability(network_sizes=[50, 100, 200], num_tests=3, max_rounds=500):
    """æµ‹è¯•Enhanced PEGASISçš„å¯æ‰©å±•æ€§"""
    print("ğŸš€ Enhanced PEGASIS å¤§è§„æ¨¡ç½‘ç»œå¯æ‰©å±•æ€§éªŒè¯")
    print("=" * 80)
    
    results = {}
    
    for size in network_sizes:
        print(f"\nğŸ“Š æµ‹è¯•ç½‘ç»œè§„æ¨¡: {size} èŠ‚ç‚¹")
        print("-" * 50)
        
        enhanced_results = []
        original_results = []
        
        for test_id in range(num_tests):
            print(f"   ç¬¬ {test_id+1}/{num_tests} æ¬¡æµ‹è¯•...")
            
            # æµ‹è¯•Enhanced PEGASIS
            enhanced_config = EnhancedPEGASISConfig(
                num_nodes=size,
                area_width=int(size * 2),  # åŠ¨æ€è°ƒæ•´åŒºåŸŸå¤§å°
                area_height=int(size * 2),
                base_station_x=size,
                base_station_y=size,
                initial_energy=2.0,
                transmission_range=30.0,
                packet_size=1024
            )
            
            enhanced_protocol = EnhancedPEGASISProtocol(enhanced_config)
            enhanced_protocol.initialize_network()
            
            start_time = time.time()
            enhanced_result = enhanced_protocol.run_simulation(max_rounds=max_rounds)
            enhanced_time = time.time() - start_time
            enhanced_result['execution_time'] = enhanced_time
            enhanced_results.append(enhanced_result)
            
            # æµ‹è¯•åŸå§‹PEGASIS
            original_config = NetworkConfig(
                num_nodes=size,
                area_width=int(size * 2),
                area_height=int(size * 2),
                base_station_x=size,
                base_station_y=size,
                initial_energy=2.0
            )
            
            energy_model = ImprovedEnergyModel(HardwarePlatform.CC2420_TELOSB)
            original_protocol = PEGASISProtocol(original_config, energy_model)
            
            start_time = time.time()
            original_result = original_protocol.run_simulation(max_rounds=max_rounds)
            original_time = time.time() - start_time
            original_result['execution_time'] = original_time
            original_results.append(original_result)
            
            # å®æ—¶æ€§èƒ½å¯¹æ¯”
            enhanced_eff = enhanced_result['energy_efficiency']
            original_eff = original_result['energy_efficiency']
            improvement = ((enhanced_eff - original_eff) / original_eff) * 100
            
            print(f"      Enhanced: {enhanced_eff:.1f} packets/J, "
                  f"Original: {original_eff:.1f} packets/J, "
                  f"æå‡: {improvement:+.1f}%")
        
        # ç»Ÿè®¡åˆ†æ
        enhanced_efficiency = [r['energy_efficiency'] for r in enhanced_results]
        original_efficiency = [r['energy_efficiency'] for r in original_results]
        enhanced_pdr = [r['packet_delivery_ratio'] for r in enhanced_results]
        original_pdr = [r['packet_delivery_ratio'] for r in original_results]
        enhanced_time = [r['execution_time'] for r in enhanced_results]
        original_time = [r['execution_time'] for r in original_results]
        
        avg_improvement = ((statistics.mean(enhanced_efficiency) - statistics.mean(original_efficiency)) / 
                          statistics.mean(original_efficiency)) * 100
        
        results[size] = {
            'enhanced_efficiency_mean': statistics.mean(enhanced_efficiency),
            'enhanced_efficiency_std': statistics.stdev(enhanced_efficiency) if len(enhanced_efficiency) > 1 else 0,
            'original_efficiency_mean': statistics.mean(original_efficiency),
            'original_efficiency_std': statistics.stdev(original_efficiency) if len(original_efficiency) > 1 else 0,
            'efficiency_improvement': avg_improvement,
            'enhanced_pdr_mean': statistics.mean(enhanced_pdr),
            'original_pdr_mean': statistics.mean(original_pdr),
            'enhanced_time_mean': statistics.mean(enhanced_time),
            'original_time_mean': statistics.mean(original_time),
            'scalability_factor': statistics.mean(enhanced_time) / (size / 50),  # ç›¸å¯¹äº50èŠ‚ç‚¹çš„æ—¶é—´å¤æ‚åº¦
            'enhanced_results': enhanced_results,
            'original_results': original_results
        }
        
        print(f"   ğŸ“ˆ å¹³å‡æ€§èƒ½æå‡: {avg_improvement:+.1f}%")
        print(f"   â±ï¸ å¹³å‡æ‰§è¡Œæ—¶é—´: Enhanced {statistics.mean(enhanced_time):.2f}s, "
              f"Original {statistics.mean(original_time):.2f}s")
    
    return results

def analyze_scalability_results(results):
    """åˆ†æå¯æ‰©å±•æ€§ç»“æœ"""
    print("\nğŸ“Š å¤§è§„æ¨¡ç½‘ç»œå¯æ‰©å±•æ€§åˆ†æ")
    print("=" * 80)
    
    sizes = sorted(results.keys())
    
    print("ğŸ“ˆ æ€§èƒ½æå‡éšç½‘ç»œè§„æ¨¡å˜åŒ–:")
    print("-" * 60)
    print(f"{'ç½‘ç»œè§„æ¨¡':<10} {'æ€§èƒ½æå‡':<12} {'èƒ½æ•ˆ(Enhanced)':<15} {'èƒ½æ•ˆ(Original)':<15} {'æ‰§è¡Œæ—¶é—´':<10}")
    print("-" * 60)
    
    improvements = []
    for size in sizes:
        data = results[size]
        improvement = data['efficiency_improvement']
        enhanced_eff = data['enhanced_efficiency_mean']
        original_eff = data['original_efficiency_mean']
        exec_time = data['enhanced_time_mean']
        
        improvements.append(improvement)
        
        print(f"{size:<10} {improvement:+.1f}%{'':<7} {enhanced_eff:<15.1f} {original_eff:<15.1f} {exec_time:<10.2f}s")
    
    # å¯æ‰©å±•æ€§è¯„ä¼°
    print(f"\nğŸ¯ å¯æ‰©å±•æ€§è¯„ä¼°:")
    min_improvement = min(improvements)
    max_improvement = max(improvements)
    avg_improvement = statistics.mean(improvements)
    
    print(f"   å¹³å‡æ€§èƒ½æå‡: {avg_improvement:.1f}%")
    print(f"   æ€§èƒ½æå‡èŒƒå›´: {min_improvement:.1f}% ~ {max_improvement:.1f}%")
    print(f"   æ€§èƒ½ç¨³å®šæ€§: {statistics.stdev(improvements):.1f}% (æ ‡å‡†å·®)")
    
    if min_improvement >= 90:
        print("   âœ… ä¼˜ç§€ï¼æ‰€æœ‰è§„æ¨¡éƒ½ä¿æŒ90%+æ€§èƒ½æå‡")
    elif min_improvement >= 50:
        print("   âš ï¸ è‰¯å¥½ï¼Œä½†å¤§è§„æ¨¡ç½‘ç»œæ€§èƒ½æœ‰æ‰€ä¸‹é™")
    else:
        print("   âŒ å¯æ‰©å±•æ€§éœ€è¦æ”¹è¿›")
    
    # æ—¶é—´å¤æ‚åº¦åˆ†æ
    print(f"\nâ±ï¸ æ—¶é—´å¤æ‚åº¦åˆ†æ:")
    for size in sizes:
        scalability_factor = results[size]['scalability_factor']
        theoretical_factor = (size / 50) * np.log(size / 50)  # O(n log n)ç†è®ºå€¼
        print(f"   {size}èŠ‚ç‚¹: å®é™…{scalability_factor:.2f}x, ç†è®º{theoretical_factor:.2f}x")
    
    return {
        'average_improvement': avg_improvement,
        'min_improvement': min_improvement,
        'max_improvement': max_improvement,
        'stability': statistics.stdev(improvements),
        'scalability_assessment': 'excellent' if min_improvement >= 90 else 'good' if min_improvement >= 50 else 'needs_improvement'
    }

def generate_scalability_charts(results):
    """ç”Ÿæˆå¯æ‰©å±•æ€§åˆ†æå›¾è¡¨"""
    sizes = sorted(results.keys())
    
    # æå–æ•°æ®
    enhanced_efficiency = [results[size]['enhanced_efficiency_mean'] for size in sizes]
    original_efficiency = [results[size]['original_efficiency_mean'] for size in sizes]
    improvements = [results[size]['efficiency_improvement'] for size in sizes]
    execution_times = [results[size]['enhanced_time_mean'] for size in sizes]
    
    # åˆ›å»ºå›¾è¡¨
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. èƒ½æ•ˆå¯¹æ¯”
    ax1.plot(sizes, enhanced_efficiency, 'b-o', label='Enhanced PEGASIS', linewidth=2, markersize=8)
    ax1.plot(sizes, original_efficiency, 'r-s', label='Original PEGASIS', linewidth=2, markersize=8)
    ax1.set_xlabel('Network Size (nodes)')
    ax1.set_ylabel('Energy Efficiency (packets/J)')
    ax1.set_title('Energy Efficiency vs Network Size')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. æ€§èƒ½æå‡
    ax2.bar(sizes, improvements, color='green', alpha=0.7, width=15)
    ax2.axhline(y=90, color='red', linestyle='--', label='90% Target')
    ax2.set_xlabel('Network Size (nodes)')
    ax2.set_ylabel('Performance Improvement (%)')
    ax2.set_title('Performance Improvement vs Network Size')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. æ‰§è¡Œæ—¶é—´
    ax3.plot(sizes, execution_times, 'purple', marker='D', linewidth=2, markersize=8)
    theoretical_times = [(size/50)**1.2 * execution_times[0] for size in sizes]  # ç†è®ºO(n^1.2)
    ax3.plot(sizes, theoretical_times, 'orange', linestyle='--', label='Theoretical O(n^1.2)')
    ax3.set_xlabel('Network Size (nodes)')
    ax3.set_ylabel('Execution Time (seconds)')
    ax3.set_title('Execution Time vs Network Size')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. æŠ•é€’ç‡å¯¹æ¯”
    enhanced_pdr = [results[size]['enhanced_pdr_mean'] for size in sizes]
    original_pdr = [results[size]['original_pdr_mean'] for size in sizes]
    ax4.plot(sizes, enhanced_pdr, 'b-o', label='Enhanced PEGASIS', linewidth=2, markersize=8)
    ax4.plot(sizes, original_pdr, 'r-s', label='Original PEGASIS', linewidth=2, markersize=8)
    ax4.set_xlabel('Network Size (nodes)')
    ax4.set_ylabel('Packet Delivery Ratio')
    ax4.set_title('Packet Delivery Ratio vs Network Size')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.set_ylim(0.9, 1.01)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    chart_path = os.path.join(os.path.dirname(__file__), '..', 'results', 
                             f'enhanced_pegasis_scalability_{timestamp}.png')
    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
    print(f"\nğŸ“Š å¯æ‰©å±•æ€§åˆ†æå›¾è¡¨å·²ä¿å­˜: enhanced_pegasis_scalability_{timestamp}.png")
    
    return chart_path

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Enhanced PEGASIS å¤§è§„æ¨¡ç½‘ç»œéªŒè¯")
    print("ç›®æ ‡: éªŒè¯ç®—æ³•å¯æ‰©å±•æ€§ï¼Œç¡®ä¿90%+æ€§èƒ½æå‡")
    print("=" * 80)
    
    try:
        # è¿è¡Œå¯æ‰©å±•æ€§æµ‹è¯•
        print("ğŸ”„ å¼€å§‹å¤§è§„æ¨¡ç½‘ç»œæµ‹è¯•...")
        results = test_scalability(
            network_sizes=[50, 100, 200], 
            num_tests=3, 
            max_rounds=300  # å‡å°‘è½®æ•°ä»¥åŠ å¿«æµ‹è¯•
        )
        
        # åˆ†æç»“æœ
        analysis = analyze_scalability_results(results)
        
        # ç”Ÿæˆå›¾è¡¨
        chart_path = generate_scalability_charts(results)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = os.path.join(os.path.dirname(__file__), '..', 'results', 
                                   f'large_scale_validation_{timestamp}.json')
        
        final_results = {
            'scalability_results': results,
            'analysis_summary': analysis,
            'chart_path': chart_path,
            'test_parameters': {
                'network_sizes': [50, 100, 200],
                'num_tests': 3,
                'max_rounds': 300
            }
        }
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜: large_scale_validation_{timestamp}.json")
        
        # æ€»ç»“
        print(f"\nğŸ‰ å¤§è§„æ¨¡ç½‘ç»œéªŒè¯å®Œæˆï¼")
        print(f"ğŸ“ˆ å¹³å‡æ€§èƒ½æå‡: {analysis['average_improvement']:.1f}%")
        print(f"ğŸ¯ å¯æ‰©å±•æ€§è¯„ä¼°: {analysis['scalability_assessment']}")
        
        if analysis['scalability_assessment'] == 'excellent':
            print("âœ… Enhanced PEGASISåœ¨å¤§è§„æ¨¡ç½‘ç»œä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ»¡è¶³Q3æœŸåˆŠè¦æ±‚ï¼")
        else:
            print("âš ï¸ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–å¤§è§„æ¨¡ç½‘ç»œæ€§èƒ½")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
